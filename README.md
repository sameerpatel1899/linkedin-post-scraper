LinkedIn Post Scraper (Python + Selenium + Flask)

A browser automation tool that scrapes detailed posts from LinkedIn based on keyword, date range, and post type. It works both via **command-line (CLI)** and a **web interface (Flask)**.

---

## ğŸš€ Features

âœ… Scrapes LinkedIn posts based on:
- Keyword or hashtag
- Date range (from â€“ to)
- Post type (text, video, image, etc.)

âœ… Extracts:
- Full post content (even with "See more")
- Post author, likes, and post date
- Output as CSV and JSON

âœ… Works with:
- CLI (terminal)
- Web UI (Flask form)

---

## ğŸ› ï¸ Tech Stack

- Python 3.x
- Selenium (browser automation)
- Flask (web UI)
- BeautifulSoup (if extended)
- Pandas (for export to CSV)

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/linkedin-post-scraper.git
cd linkedin-post-scraper
````

### 2. Create Virtual Environment (Recommended)

```bash
python -m venv env
```

Activate it:

* On Windows:

  ```bash
  .\env\Scripts\activate
  ```
* On Mac/Linux:

  ```bash
  source env/bin/activate
  ```

### 3. Install Required Libraries

```bash
pip install -r backend/requirements.txt
```

---

## ğŸ” 4. Log into LinkedIn & Save Cookies (One Time)

You must login manually once to authenticate your session.

### Run this:

```bash
cd backend
python
```

Then inside the Python shell:

```python
from scraper.linkedin_auth import login_and_save_cookies
login_and_save_cookies()
```

A Chrome browser will open. **Manually log into LinkedIn**, wait 60 seconds. Cookies will be saved.

Type `exit()` to leave Python.

âœ… Done! Now you can scrape without logging in again.

---

## âœ… CLI Mode (Terminal)

```bash
cd backend
python main.py
```

Youâ€™ll be asked:

```
Enter keyword or hashtag: hiring
Start date (YYYY-MM-DD): 2024-01-01
End date (YYYY-MM-DD): 2024-12-31
Post type filter (text, image, video, etc): text
```

âœ… It will:

* Launch browser
* Scroll through LinkedIn
* Scrape matching posts
* Save to:

  * `output/scraped_posts.csv`
  * `output/scraped_posts.json`

---

## ğŸŒ Web App Mode (Flask)

To use the UI:

```bash
cd frontend
python app.py
```

Open browser:

```
http://127.0.0.1:5000/
```

### On the Web Form:

* Enter keyword (e.g., "hiring")
* Pick a start date and end date
* Select post type (text/image/etc.)
* Click **Scrape**

âœ… It will:

* Show loading message
* Open browser and scrape
* Display results on screen
* Save files to `/output/` folder

---

## ğŸ§¹ Project Structure

```
linkedin-post-scraper/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraper/         # Contains LinkedIn scraper and auth
â”‚   â”œâ”€â”€ utils/           # Export to CSV/JSON
â”‚   â”œâ”€â”€ main.py          # CLI entry point
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ templates/       # HTML form (index.html)
â”‚   â””â”€â”€ app.py           # Flask app
â”‚
â”œâ”€â”€ output/              # Scraped data gets saved here
â”œâ”€â”€ cookies.pkl          # Saved LinkedIn session cookies (not in Git)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš ï¸ Notes

* âŒ Do **not** share or upload `cookies.pkl` to GitHub.
* â›” This tool is for **educational/personal use only.**
* ğŸ›‘ Scraping LinkedIn may violate their TOS. Use responsibly.

---

## ğŸ™Œ Credits

Built with â¤ï¸ by Sameer Patel
sameerpatelgo@gmail.com

Contributions, improvements, and ideas welcome!

```
